from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import ConversationChain
from langchain_community.chat_models import ChatOpenAI as CommunityChatOpenAI
from langchain_community.chat_message_histories import RedisChatMessageHistory
from langchain.memory import ConversationBufferMemory
from dotenv import dotenv_values
from chatlog import Session, ChatLog

config = dotenv_values(".env")
llm = ChatOpenAI(api_key=config.get("OPENAI_API_KEY"), model="gpt-4o")

message_history = RedisChatMessageHistory(
    session_id="my-session",
    url="redis://localhost:6379"
)
memory = ConversationBufferMemory(memory_key="history", chat_memory=message_history, return_messages=True)
conversation = ConversationChain(llm=llm, memory=memory)

print("ä½ æƒ³å• AI ä»€éº¼ï¼Ÿï¼ˆè¼¸å…¥ 'bye' çµæŸï¼‰ï¼š")
while True:
    user_input = input("\nä½ ï¼š")
    if user_input.lower() == "bye":
        break
    if user_input == "/ç´€éŒ„":
        # é¡¯ç¤ºæ‰€æœ‰å°è©±ç´€éŒ„ï¼ˆé€™æ®µé‚è¼¯æœƒé˜»æ“‹å‚³å…¥ AIï¼‰
        session = Session()
        logs = session.query(ChatLog).all()
        for log in logs:
            print(f"ğŸ‘¤ ä½ èªªï¼š{log.user_input}")
            print(f"ğŸ¤– AI å›ç­”ï¼š{log.ai_response}")
            print("-" * 40)
        continue

    answer = conversation.predict(input=user_input)
    print("\nğŸ¤– AIï¼š", answer)

    # å„²å­˜å°è©±é€²è³‡æ–™åº«
    session = Session()
    chat = ChatLog(user_input=user_input, ai_response=answer)
    session.add(chat)
    session.commit()